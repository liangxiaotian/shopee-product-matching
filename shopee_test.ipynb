{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shopee_test.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS-vFFUPWHTi"
      },
      "source": [
        "!nvidia-smi\n",
        "!fuser -v /dev/nvidia0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTSMPCo-eEnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4652769-b77d-4003-ea47-b9b99d3f2975"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1bHHQpMs6_e",
        "outputId": "15ac6ccf-cd8d-48be-e4e1-66342930e101"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9qnx6noWopA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f09aea5-e4c1-4efb-ac8c-6d279ff09618"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "import albumentations\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02U43ruWYgkd"
      },
      "source": [
        "class CFG:\n",
        "    seed = 54\n",
        "    classes = 11014 \n",
        "    scale = 30 \n",
        "    margin = 0.5\n",
        "    fc_dim = 512\n",
        "    img_size = 380  #对应EfficientNetB4的输入分辨率 \n",
        "    batch_size = 8\n",
        "    channels = 3"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IWqrKhhX69D"
      },
      "source": [
        "def read_dataset(csv_path, image_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    image_paths = image_path + df['image']\n",
        "    return df, image_paths"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr5dHl1aapxF"
      },
      "source": [
        "image_path = '/content/drive/MyDrive/shopee/shopee-product-matching/test_images/'\n",
        "csv_path = '/content/drive/MyDrive/shopee/shopee-product-matching/test.csv' # repalce the train.csv\n",
        "df, image_paths = read_dataset(csv_path, image_path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "JpRLlkKILTN3",
        "outputId": "c59acfd6-8f2d-42de-ce71-e5b3b295b939"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posting_id</th>\n",
              "      <th>image</th>\n",
              "      <th>image_phash</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test_2255846744</td>\n",
              "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
              "      <td>ecc292392dc7687a</td>\n",
              "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test_3588702337</td>\n",
              "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
              "      <td>e9968f60d2699e2c</td>\n",
              "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test_4015706929</td>\n",
              "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
              "      <td>ba81c17e3581cabe</td>\n",
              "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        posting_id  ...                                              title\n",
              "0  test_2255846744  ...  Edufuntoys - CHARACTER PHONE ada lampu dan mus...\n",
              "1  test_3588702337  ...  (Beli 1 Free Spatula) Masker Komedo | Blackhea...\n",
              "2  test_4015706929  ...   READY Lemonilo Mie instant sehat kuah dan goreng\n",
              "\n",
              "[3 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759wmyPtasMv"
      },
      "source": [
        "def f1_score(y_true, y_pred):\n",
        "    y_true = y_true.apply(lambda x: set(x.split()))\n",
        "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
        "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
        "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
        "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
        "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
        "    return f1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIxP88Qfmdyn"
      },
      "source": [
        "def get_image_neighbors(df, embeddings, KNN=50):\n",
        "\n",
        "    model = NearestNeighbors(n_neighbors = KNN)\n",
        "    model.fit(embeddings)\n",
        "    distances, indices = model.kneighbors(embeddings)\n",
        "    \n",
        "    threshold = 4.5\n",
        "    predictions = []\n",
        "    for k in tqdm(range(embeddings.shape[0])):\n",
        "        idx = np.where(distances[k,] < threshold)[0]\n",
        "        ids = indices[k,idx]\n",
        "        posting_ids = df['posting_id'].iloc[ids].values\n",
        "        predictions.append(posting_ids)\n",
        "        \n",
        "    del model, distances, indices\n",
        "    gc.collect()\n",
        "    return df, predictions"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LGuQaqnasU_"
      },
      "source": [
        "# Arcmarginproduct class keras layer\n",
        "class ArcMarginProduct(tf.keras.layers.Layer):\n",
        "    '''\n",
        "    Implements large margin arc distance.\n",
        "\n",
        "    Reference:\n",
        "        https://arxiv.org/pdf/1801.07698.pdf\n",
        "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
        "            blob/master/src/modeling/metric_learning.py\n",
        "    '''\n",
        "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
        "                 ls_eps=0.0, **kwargs):\n",
        "\n",
        "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.ls_eps = ls_eps\n",
        "        self.easy_margin = easy_margin\n",
        "        self.cos_m = tf.math.cos(m)\n",
        "        self.sin_m = tf.math.sin(m)\n",
        "        self.th = tf.math.cos(math.pi - m)\n",
        "        self.mm = tf.math.sin(math.pi - m) * m\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'n_classes': self.n_classes,\n",
        "            's': self.s,\n",
        "            'm': self.m,\n",
        "            'ls_eps': self.ls_eps,\n",
        "            'easy_margin': self.easy_margin,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(ArcMarginProduct, self).build(input_shape[0])\n",
        "\n",
        "        self.W = self.add_weight(\n",
        "            name='W',\n",
        "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
        "            initializer='glorot_uniform',\n",
        "            dtype='float32',\n",
        "            trainable=True,\n",
        "            regularizer=None)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        X, y = inputs\n",
        "        y = tf.cast(y, dtype=tf.int32)\n",
        "        cosine = tf.matmul(\n",
        "            tf.math.l2_normalize(X, axis=1),\n",
        "            tf.math.l2_normalize(self.W, axis=0)\n",
        "        )\n",
        "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if self.easy_margin:\n",
        "            phi = tf.where(cosine > 0, phi, cosine)\n",
        "        else:\n",
        "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        one_hot = tf.cast(\n",
        "            tf.one_hot(y, depth=self.n_classes),\n",
        "            dtype=cosine.dtype\n",
        "        )\n",
        "        if self.ls_eps > 0:\n",
        "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
        "\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        output *= self.s\n",
        "        return output"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zTETR7gasbR"
      },
      "source": [
        "\n",
        "class EffModel(Model):\n",
        "    def __init__(self, n_classes = CFG.classes,\n",
        "        img_size = CFG.img_size,\n",
        "        fc_dim = CFG.fc_dim\n",
        "        ):\n",
        "        super(EffModel, self).__init__()\n",
        "        \n",
        "        inputs = layers.Input(shape=(img_size, img_size, 3))\n",
        "        #inputs = albumentations(inputs)\n",
        "        self.backbone = EfficientNetB4(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
        "        \n",
        "        # Freeze the pretrained weights\n",
        "        # self.backbone.trainable = False\n",
        "        \n",
        "        self.pooling = layers.GlobalAveragePooling2D(name=\"avg_pool\")\n",
        "        self.flatten = layers.Flatten()\n",
        "        \n",
        "        # Rebuild top\n",
        "        #self.dropout = layers.Dropout(rate = 0.1, name=\"dropout\")\n",
        "        self.classifier = layers.Dense(fc_dim, activation=\"relu\", name=\"pred\") # rule\n",
        "        #self.bn = layers.BatchNormalization()      \n",
        "\n",
        "    def call(self, inputs):\n",
        "        features = self.extract_features(inputs) \n",
        "        return features\n",
        "    \n",
        "    def extract_features(self, x):\n",
        "        # effnet + pooling + fc\n",
        "        x = self.backbone(x)\n",
        "        x = self.pooling(x)   \n",
        "        x = self.flatten(x) \n",
        "\n",
        "        #x = self.dropout(x)\n",
        "        x = self.classifier(x)\n",
        "        # x = self.bn(x)\n",
        "            \n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHJYIJddbYD1"
      },
      "source": [
        "# Function to decode our images\n",
        "def preprocess_image(image):\n",
        "    \n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)  \n",
        "    image = tf.image.resize(image, [CFG.img_size, CFG.img_size])\n",
        "    return image\n",
        "\n",
        "# Function to read our test image and return image\n",
        "def load_and_preprocess_image(image, label):\n",
        "    image = tf.io.read_file(image)\n",
        "    image = preprocess_image(image)\n",
        "    return image, label\n",
        "\n",
        "def get_dataset(image, label):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image, label))\n",
        "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls = AUTO) \n",
        "    # dataset = dataset.map(data_augment, num_parallel_calls=AUTO) # data_augment\n",
        "    return dataset\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwMMf_NTCUiW"
      },
      "source": [
        "\n",
        "# 1. datasets\n",
        "dataset = get_dataset(image_paths, tf.zeros(shape=len(image_paths)))\n",
        "\n",
        "# split the datasets\n",
        "test_ds = dataset.cache(filename='./cache.tf-data').shuffle(CFG.batch_size*20).batch(CFG.batch_size).prefetch(AUTO)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBm3NIWsRF71"
      },
      "source": [
        "def create_model():\n",
        "\n",
        "    backbone = EffModel()\n",
        "\n",
        "    margin = ArcMarginProduct(n_classes = CFG.classes, \n",
        "                  s = 30, \n",
        "                  m = 0.5, \n",
        "                  name='head/arc_margin', \n",
        "                  dtype='float32'\n",
        "                  )\n",
        "\n",
        "    image = tf.keras.layers.Input(shape=(CFG.img_size, CFG.img_size, 3), name='input/image')\n",
        "    label = tf.keras.layers.Input((), name='input/label')\n",
        "\n",
        "    x = backbone(image) \n",
        "    x = margin([x, label]) # Archead\n",
        "\n",
        "    model = tf.keras.models.Model(inputs = [image, label], outputs = x)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf9nUdwajlRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80585a24-d963-4fed-fecd-c10a26c13883"
      },
      "source": [
        "reconstructed_model = create_model()\n",
        "reconstructed_model.load_weights(saved_model_path)\n",
        "# 重新取输入和输出 选取embedding层作为输出\n",
        "reconstructed_model = tf.keras.models.Model(inputs = reconstructed_model.input[0], outputs = reconstructed_model.layers[-3].output) \n",
        "reconstructed_model.build((None, 380, 380, 3))\n",
        "reconstructed_model.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
            "71688192/71686520 [==============================] - 1s 0us/step\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input/image (InputLayer)     [(None, 380, 380, 3)]     0         \n",
            "_________________________________________________________________\n",
            "eff_model_3 (EffModel)       (None, 512)               18593887  \n",
            "=================================================================\n",
            "Total params: 18,593,887\n",
            "Trainable params: 919,040\n",
            "Non-trainable params: 17,674,847\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NenF1UR6b9Tf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186f8beb-e337-44cf-cc47-30e58c570013"
      },
      "source": [
        "embeds = []\n",
        "for images, labels in tqdm(test_ds):\n",
        "      embeds.append(reconstructed_model.predict(images))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 172/172 [00:40<00:00,  4.20it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyXKKsAl_otj"
      },
      "source": [
        "def get_text_predictions(df, max_features=25000):\n",
        "    \n",
        "    model = TfidfVectorizer(stop_words='english', binary=True, max_features=max_features)\n",
        "    text_embeddings = model.fit_transform(df['title']).toarray()\n",
        "\n",
        "    print('Finding similar titles...')\n",
        "    CHUNK = 1024 * 4\n",
        "    CTS = len(df) // CHUNK\n",
        "    if (len(df)%CHUNK) != 0:\n",
        "        CTS += 1\n",
        "\n",
        "    preds = []\n",
        "    for j in range( CTS ):\n",
        "        a = j * CHUNK\n",
        "        b = (j+1) * CHUNK\n",
        "        b = min(b, len(df))\n",
        "        print('chunk', a, 'to', b)\n",
        "\n",
        "        # COSINE SIMILARITY DISTANCE\n",
        "        cts = np.matmul(text_embeddings, text_embeddings[a:b].T).T\n",
        "        for k in range(b-a):\n",
        "            IDX = np.where(cts[k,]>0.75)[0]\n",
        "            o = df.iloc[np.asarray(IDX)].posting_id.values\n",
        "            preds.append(o)\n",
        "\n",
        "    del model,text_embeddings\n",
        "    gc.collect()\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWW3hiRq_sYu",
        "outputId": "7289d537-2bbb-4921-9394-9e2d1d8ebb8b"
      },
      "source": [
        "text_predictions = get_text_predictions(df, max_features=25000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finding similar titles...\n",
            "chunk 0 to 3425\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mFWRGQvcL77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38fd8a65-e635-483f-b4f5-52321dbbf70f"
      },
      "source": [
        "image_embeddings = np.concatenate(embeds)\n",
        "df, image_predictions = get_image_neighbors(df, image_embeddings, KNN = 3) # "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3425/3425 [00:00<00:00, 9704.10it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOGN0nyuLAd2"
      },
      "source": [
        "def combine_predictions(row):\n",
        "    x = np.concatenate([row['image_predictions'], row['text_predictions']])\n",
        "    return ' '.join( np.unique(x) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwngPcJgmWeS"
      },
      "source": [
        "df['image_predictions'] = image_predictions\n",
        "df['text_predictions'] = text_predictions\n",
        "df['matches'] = df.apply(combine_predictions, axis=1)\n",
        "df[['posting_id', 'matches']].to_csv('/content/drive/MyDrive/shopee/outputs/submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iEH4N72Aij5"
      },
      "source": [
        "df['f1'] = f1_score(df['posting_id'], df['matches'])\n",
        "df['f1'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eewMREkFMGWB",
        "outputId": "69cf53d8-0182-4f5c-a589-66df72ab4386"
      },
      "source": [
        "df[['posting_id','image_predictions', 'text_predictions', 'matches', 'f1']].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posting_id</th>\n",
              "      <th>image_predictions</th>\n",
              "      <th>text_predictions</th>\n",
              "      <th>matches</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>912</th>\n",
              "      <td>train_192154327</td>\n",
              "      <td>[train_192154327, train_4249618609, train_1532...</td>\n",
              "      <td>[train_192154327]</td>\n",
              "      <td>train_153214025 train_192154327 train_4249618609</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24857</th>\n",
              "      <td>train_3602971377</td>\n",
              "      <td>[train_3602971377, train_2834821897, train_223...</td>\n",
              "      <td>[train_3602971377]</td>\n",
              "      <td>train_2231906914 train_2834821897 train_360297...</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7276</th>\n",
              "      <td>train_4280407716</td>\n",
              "      <td>[train_4280407716, train_181310095, train_1182...</td>\n",
              "      <td>[train_4280407716]</td>\n",
              "      <td>train_1182906906 train_181310095 train_4280407716</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21442</th>\n",
              "      <td>train_898978553</td>\n",
              "      <td>[train_898978553, train_750786421, train_38098...</td>\n",
              "      <td>[train_898978553]</td>\n",
              "      <td>train_3809881145 train_750786421 train_898978553</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8190</th>\n",
              "      <td>train_2680742165</td>\n",
              "      <td>[train_2680742165, train_3540642385, train_977...</td>\n",
              "      <td>[train_2680742165]</td>\n",
              "      <td>train_2680742165 train_3540642385 train_977743751</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             posting_id  ...   f1\n",
              "912     train_192154327  ...  0.5\n",
              "24857  train_3602971377  ...  0.5\n",
              "7276   train_4280407716  ...  0.5\n",
              "21442   train_898978553  ...  0.5\n",
              "8190   train_2680742165  ...  0.5\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    }
  ]
}