{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shopee_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS-vFFUPWHTi",
        "outputId": "471f3d73-286c-4923-aa86-b992ed691f4a"
      },
      "source": [
        "!nvidia-smi\n",
        "!fuser -v /dev/nvidia0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n",
            "Specified filename /dev/nvidia0 does not exist.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msEJC9ps8thh",
        "outputId": "9fdb3c31-e4ed-4675-b6e0-2154f3ade6e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj8wAa9bbFLt",
        "outputId": "4caaba50-d989-4c51-973e-0049fd0ca8cb"
      },
      "source": [
        "!kill -9 2432  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: kill: (2432) - No such process\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTSMPCo-eEnd",
        "outputId": "bc0c840f-d10e-4d55-8591-44d75464cce9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1bHHQpMs6_e",
        "outputId": "d64c4668-20c7-4e42-e772-76fa509e913e"
      },
      "source": [
        "!ls                                      "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9qnx6noWopA",
        "outputId": "97facd9b-6a16-40b1-9606-9ccc2c7c696e"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "import albumentations\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02U43ruWYgkd"
      },
      "source": [
        "class CFG:\n",
        "    seed = 54\n",
        "    classes = 11014 \n",
        "    scale = 30 \n",
        "    margin = 0.5\n",
        "    fc_dim = 512\n",
        "    img_size = 380  #对应EfficientNetB4的输入分辨率 \n",
        "    batch_size = 8\n",
        "    channels = 3"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IWqrKhhX69D"
      },
      "source": [
        "def read_dataset(csv_path, image_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    image_paths = image_path + df['image']\n",
        "    return df, image_paths"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr5dHl1aapxF"
      },
      "source": [
        "image_path = '/content/drive/MyDrive/shopee/shopee-product-matching/train_images/'\n",
        "csv_path = '/content/drive/MyDrive/shopee/shopee-product-matching/train_r.csv' # repalce the train.csv\n",
        "df, image_paths = read_dataset(csv_path, image_path)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnlUBUulLEFT"
      },
      "source": [
        "# # The pictures pulled out by kaggle are not complete, so you need to delete related non-existent paths\n",
        "# df['isexist'] = df.apply(lambda x: 1 if os.path.isfile(image_path + x['image']) else 0, axis = 1)\n",
        "# df = df[df['isexist'] == 1]\n",
        "# df.drop(columns = ['isexist'], inplace=True)\n",
        "# df.to_csv('/content/drive/MyDrive/shopee/shopee-product-matching/train_r.csv', sep = ',', index_col=None)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ktBubcAdZGxy",
        "outputId": "6d5f470f-b396-4284-bdc2-022000609aaa"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posting_id</th>\n",
              "      <th>image</th>\n",
              "      <th>image_phash</th>\n",
              "      <th>title</th>\n",
              "      <th>label_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_3386243561</td>\n",
              "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
              "      <td>af3f9460c2838f0f</td>\n",
              "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
              "      <td>2937985045</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_2288590299</td>\n",
              "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
              "      <td>b94cb00ed3e50f78</td>\n",
              "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
              "      <td>2395904891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2406599165</td>\n",
              "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
              "      <td>8514fc58eafea283</td>\n",
              "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
              "      <td>4093212188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3369186413</td>\n",
              "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
              "      <td>a6f319f924ad708c</td>\n",
              "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
              "      <td>3648931069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_2464356923</td>\n",
              "      <td>0013e7355ffc5ff8fb1ccad3e42d92fe.jpg</td>\n",
              "      <td>bbd097a7870f4a50</td>\n",
              "      <td>CELANA WANITA  (BB 45-84 KG)Harem wanita (bisa...</td>\n",
              "      <td>2660605217</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         posting_id  ... label_group\n",
              "0  train_3386243561  ...  2937985045\n",
              "1  train_2288590299  ...  2395904891\n",
              "2  train_2406599165  ...  4093212188\n",
              "3  train_3369186413  ...  3648931069\n",
              "4  train_2464356923  ...  2660605217\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R87o28q-YaKD"
      },
      "source": [
        "label2id = dict(zip(range(df.label_group.nunique()),df.label_group.unique()))\n",
        "id2label = dict(zip(df.label_group.unique(),range(df.label_group.nunique())))\n",
        "df[\"labels\"] = df[\"label_group\"].map(id2label)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5jfpk8I_Z3D1",
        "outputId": "3040c5c1-a6ad-4550-f2a7-15c5f947ddae"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posting_id</th>\n",
              "      <th>image</th>\n",
              "      <th>image_phash</th>\n",
              "      <th>title</th>\n",
              "      <th>label_group</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_3386243561</td>\n",
              "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
              "      <td>af3f9460c2838f0f</td>\n",
              "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
              "      <td>2937985045</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_2288590299</td>\n",
              "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
              "      <td>b94cb00ed3e50f78</td>\n",
              "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
              "      <td>2395904891</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2406599165</td>\n",
              "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
              "      <td>8514fc58eafea283</td>\n",
              "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
              "      <td>4093212188</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3369186413</td>\n",
              "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
              "      <td>a6f319f924ad708c</td>\n",
              "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
              "      <td>3648931069</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_2464356923</td>\n",
              "      <td>0013e7355ffc5ff8fb1ccad3e42d92fe.jpg</td>\n",
              "      <td>bbd097a7870f4a50</td>\n",
              "      <td>CELANA WANITA  (BB 45-84 KG)Harem wanita (bisa...</td>\n",
              "      <td>2660605217</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         posting_id                                 image  ... label_group labels\n",
              "0  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  ...  2937985045      0\n",
              "1  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  ...  2395904891      1\n",
              "2  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  ...  4093212188      2\n",
              "3  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  ...  3648931069      3\n",
              "4  train_2464356923  0013e7355ffc5ff8fb1ccad3e42d92fe.jpg  ...  2660605217      4\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG7ygTY6cNHB"
      },
      "source": [
        "# train_df, test_df = train_test_split(df, test_size = 0.1)\n",
        "# train_image_paths, test_image_paths = train_test_split(image_paths, test_size = 0.1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759wmyPtasMv"
      },
      "source": [
        "def f1_score(y_true, y_pred):\n",
        "    y_true = y_true.apply(lambda x: set(x.split()))\n",
        "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
        "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
        "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
        "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
        "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
        "    return f1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIxP88Qfmdyn"
      },
      "source": [
        "def get_image_neighbors(df, embeddings, KNN=50):\n",
        "\n",
        "    model = NearestNeighbors(n_neighbors = KNN)\n",
        "    model.fit(embeddings)\n",
        "    distances, indices = model.kneighbors(embeddings)\n",
        "    \n",
        "    threshold = 4.5\n",
        "    predictions = []\n",
        "    for k in tqdm(range(embeddings.shape[0])):\n",
        "        idx = np.where(distances[k,] < threshold)[0]\n",
        "        ids = indices[k,idx]\n",
        "        posting_ids = df['posting_id'].iloc[ids].values\n",
        "        predictions.append(posting_ids)\n",
        "        \n",
        "    del model, distances, indices\n",
        "    gc.collect()\n",
        "    return df, predictions"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_pSb21obyjU"
      },
      "source": [
        "def data_augment(image, label):\n",
        "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "            \n",
        "    # Flips\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    if p_spatial > .75:\n",
        "        image = tf.image.transpose(image)\n",
        "        \n",
        "    # Rotates\n",
        "    if p_rotate > .75:\n",
        "        image = tf.image.rot90(image, k=3) \n",
        "    elif p_rotate > .5:\n",
        "        image = tf.image.rot90(image, k=2) \n",
        "    elif p_rotate > .25:\n",
        "        image = tf.image.rot90(image, k=1) \n",
        "        \n",
        "    \n",
        "    if p_pixel_1 >= .4:\n",
        "        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
        "    if p_pixel_2 >= .4:\n",
        "        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n",
        "    if p_pixel_3 >= .4:\n",
        "        image = tf.image.random_brightness(image, max_delta=.1)\n",
        "        \n",
        "    \n",
        "    if p_crop > .7:\n",
        "        if p_crop > .9:\n",
        "            image = tf.image.central_crop(image, central_fraction=.7)\n",
        "        elif p_crop > .8:\n",
        "            image = tf.image.central_crop(image, central_fraction=.8)\n",
        "        else:\n",
        "            image = tf.image.central_crop(image, central_fraction=.9)\n",
        "    elif p_crop > .4:\n",
        "        crop_size = tf.random.uniform([], int(CFG.img_size*.8), CFG.img_size, dtype=tf.int32)\n",
        "        image = tf.image.random_crop(image, size=[crop_size, crop_size, CFG.channels])\n",
        "    \n",
        "    image = tf.image.resize(image, [CFG.img_size, CFG.img_size])\n",
        "    return image, label"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHJYIJddbYD1"
      },
      "source": [
        "# Function to decode our images\n",
        "def preprocess_image(image):\n",
        "    \n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)  # / 255.0  # normalize to [0,1], but effnet has normlayer\n",
        "    image = tf.image.resize(image, [CFG.img_size, CFG.img_size])\n",
        "    return image\n",
        "\n",
        "# Function to read our test image and return image\n",
        "def load_and_preprocess_image(image, label):\n",
        "    image = tf.io.read_file(image)\n",
        "    image = preprocess_image(image)\n",
        "    return image, label\n",
        "\n",
        "def get_dataset(image, label):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image, label))\n",
        "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls = AUTO) \n",
        "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO) # data_augment\n",
        "    return dataset\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARGZL5cDdmUM"
      },
      "source": [
        "SPLIT = int(0.8*len(df))\n",
        "# 1. datasets\n",
        "dataset = get_dataset(image_paths, df.labels)\n",
        "train_ds = dataset.take(SPLIT)\n",
        "val_ds = dataset.skip(SPLIT)\n",
        "\n",
        "# split the datasets\n",
        "train_ds = train_ds.cache().repeat().shuffle(CFG.batch_size*20).batch(CFG.batch_size).prefetch(AUTO)\n",
        "val_ds = val_ds.cache().batch(CFG.batch_size).prefetch(AUTO) # no shuffle on test"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9EzDJR4ghXO"
      },
      "source": [
        "# Arcmarginproduct class keras layer\n",
        "class ArcMarginProduct(tf.keras.layers.Layer):\n",
        "    '''\n",
        "    Implements large margin arc distance.\n",
        "\n",
        "    Reference:\n",
        "        https://arxiv.org/pdf/1801.07698.pdf\n",
        "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
        "            blob/master/src/modeling/metric_learning.py\n",
        "    '''\n",
        "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
        "                 ls_eps=0.0, **kwargs):\n",
        "\n",
        "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.ls_eps = ls_eps\n",
        "        self.easy_margin = easy_margin\n",
        "        self.cos_m = tf.math.cos(m)\n",
        "        self.sin_m = tf.math.sin(m)\n",
        "        self.th = tf.math.cos(math.pi - m)\n",
        "        self.mm = tf.math.sin(math.pi - m) * m\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'n_classes': self.n_classes,\n",
        "            's': self.s,\n",
        "            'm': self.m,\n",
        "            'ls_eps': self.ls_eps,\n",
        "            'easy_margin': self.easy_margin,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(ArcMarginProduct, self).build(input_shape[0])\n",
        "\n",
        "        self.W = self.add_weight(\n",
        "            name='W',\n",
        "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
        "            initializer='glorot_uniform',\n",
        "            dtype='float32',\n",
        "            trainable=True,\n",
        "            regularizer=None)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        X, y = inputs\n",
        "        y = tf.cast(y, dtype=tf.int32)\n",
        "        cosine = tf.matmul(\n",
        "            tf.math.l2_normalize(X, axis=1),\n",
        "            tf.math.l2_normalize(self.W, axis=0)\n",
        "        )\n",
        "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if self.easy_margin:\n",
        "            phi = tf.where(cosine > 0, phi, cosine)\n",
        "        else:\n",
        "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        one_hot = tf.cast(\n",
        "            tf.one_hot(y, depth=self.n_classes),\n",
        "            dtype=cosine.dtype\n",
        "        )\n",
        "        if self.ls_eps > 0:\n",
        "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
        "\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        output *= self.s\n",
        "        return output"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjO76NHTgbE2"
      },
      "source": [
        "\n",
        "class EffModel(Model):\n",
        "    def __init__(self, n_classes = CFG.classes,\n",
        "        img_size = CFG.img_size,\n",
        "        fc_dim = CFG.fc_dim\n",
        "        ):\n",
        "        super(EffModel, self).__init__()\n",
        "        \n",
        "        inputs = layers.Input(shape=(img_size, img_size, 3))\n",
        "        #inputs = albumentations(inputs)\n",
        "        self.backbone = EfficientNetB4(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
        "        \n",
        "        # Freeze the pretrained weights\n",
        "        self.backbone.trainable = False\n",
        "        \n",
        "        self.pooling = layers.GlobalAveragePooling2D(name=\"avg_pool\")\n",
        "        self.flatten = layers.Flatten()\n",
        "        \n",
        "        # Rebuild top\n",
        "        self.dropout = layers.Dropout(rate = 0.1, name=\"dropout\")\n",
        "        self.classifier = layers.Dense(fc_dim, activation=\"relu\", name=\"pred\") # rule\n",
        "        self.bn = layers.BatchNormalization()      \n",
        "\n",
        "    def call(self, inputs):\n",
        "        features = self.extract_features(inputs) \n",
        "        return features\n",
        "    \n",
        "    def extract_features(self, x):\n",
        "        # effnet + pooling + fc\n",
        "        x = self.backbone(x)\n",
        "        x = self.pooling(x)   \n",
        "        x = self.flatten(x) \n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = self.classifier(x)\n",
        "        x = self.bn(x)\n",
        "            \n",
        "        return x"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBm3NIWsRF71"
      },
      "source": [
        "\n",
        "def create_model():\n",
        "\n",
        "    backbone = EffModel()\n",
        "\n",
        "    margin = ArcMarginProduct(n_classes = CFG.classes, \n",
        "                  s = 30, \n",
        "                  m = 0.5, \n",
        "                  name='head/arc_margin', \n",
        "                  dtype='float32'\n",
        "                  )\n",
        "\n",
        "    image = tf.keras.layers.Input(shape=(CFG.img_size, CFG.img_size, 3), name='input/image')\n",
        "    label = tf.keras.layers.Input((), name='input/label')\n",
        "\n",
        "    x = backbone(image) \n",
        "    x = margin([x, label]) # Archead\n",
        "\n",
        "    model = tf.keras.models.Model(inputs = [image, label], outputs = x)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw8x3AEzfPbn",
        "outputId": "ee9441a5-a5af-44a8-e710-06eda0ead13e"
      },
      "source": [
        "# 2. create_model\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
            "71688192/71686520 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input/image (InputLayer)        [(None, 380, 380, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "eff_model (EffModel)            (None, 512)          18593887    input/image[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input/label (InputLayer)        [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "head/arc_margin (ArcMarginProdu (None, 11014)        5639168     eff_model[0][0]                  \n",
            "                                                                 input/label[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 24,233,055\n",
            "Trainable params: 6,558,208\n",
            "Non-trainable params: 17,674,847\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TjS89MmfUMV"
      },
      "source": [
        "# 3. loss and test\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "mean_accuracy_train = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBY3JX-tfeZF"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMXN4w8QCiw_"
      },
      "source": [
        "# Save the model, because colab will crash at any time\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer = optimizer, model = model)\n",
        "\n",
        "manager = tf.train.CheckpointManager(ckpt, '/content/drive/MyDrive/shopee/my_model', max_to_keep=2)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyWr8pvqbiD6"
      },
      "source": [
        "# 手动保存权重\n",
        "\n",
        "def training_model():\n",
        "  \n",
        "    Epochs = 50\n",
        "    ckpt.restore(manager.latest_checkpoint)\n",
        "\n",
        "    if manager.latest_checkpoint:\n",
        "      print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "    else:\n",
        "      print(\"Initializing from scratch.\")\n",
        "\n",
        "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "    train_acc = tf.keras.metrics.Mean(name='train_acc')\n",
        "    test_acc = tf.keras.metrics.Mean(name='test_acc')\n",
        " \n",
        "    def train_step(images, labels):\n",
        "        with tf.GradientTape() as tape:\n",
        "            probs = model([images, labels], training = True)\n",
        "            loss = loss_object(labels, probs)\n",
        "            acc = mean_accuracy_train(labels, probs)\n",
        "\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        " \n",
        "        train_loss(loss)\n",
        "        train_acc(acc)\n",
        " \n",
        "    def test_step(images, labels):\n",
        "        probs = model([images, labels], training = False)\n",
        "        loss = loss_object(labels, probs)\n",
        "        acc = mean_accuracy_train(labels, probs)\n",
        "\n",
        "        test_loss(loss)\n",
        "        test_acc(acc)\n",
        " \n",
        "    for epoch in tqdm(range(Epochs)):\n",
        "\n",
        "        train_loss.reset_states()\n",
        "        test_loss.reset_states()\n",
        "\n",
        "        train_acc.reset_states()\n",
        "        test_acc.reset_states()\n",
        "\n",
        "\n",
        "        for images, labels in train_ds:\n",
        "            train_step(images, labels)\n",
        "\n",
        "            ckpt.step.assign_add(1) \n",
        "            if int(ckpt.step) % 100 == 0:\n",
        "              p_out = 'loss: {}, acc: {}'\n",
        "              print(p_out.format(train_loss.result().numpy(), train_acc.result().numpy()))\n",
        "\n",
        "            if int(ckpt.step) % 500 == 0:\n",
        "              save_path = manager.save()\n",
        "              print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
        "        \n",
        "        for images, labels in val_ds:\n",
        "            test_step(images, labels)\n",
        " \n",
        "        tmp = 'Epoch: {}, train_loss: {}, test_loss: {}, train_acc: {}, test_acc: {}'\n",
        "        print(tmp.format(epoch+1, train_loss.result(), test_loss.result(),train_acc.result(), test_acc.result()))\n",
        "\n",
        "        \n",
        "    return model\n",
        "\n",
        "model = training_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXeAMd05TiRJ"
      },
      "source": [
        "saved_model_path = \"/content/drive/MyDrive/shopee/my_model/\"\n",
        "model.save_weights(saved_model_path)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf9nUdwajlRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "746e7fd0-654f-4d0e-cb51-c55bee3442fb"
      },
      "source": [
        "reconstructed_model = create_model()\n",
        "reconstructed_model.load_weights(saved_model_path)\n",
        "# 重新取输入和输出 选取embedding层作为输出\n",
        "reconstructed_model = tf.keras.models.Model(inputs = reconstructed_model.input[0], outputs = reconstructed_model.layers[-3].output) \n",
        "reconstructed_model.build((None, 380, 380, 3))\n",
        "reconstructed_model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input/image (InputLayer)     [(None, 380, 380, 3)]     0         \n",
            "_________________________________________________________________\n",
            "eff_model_3 (EffModel)       (None, 512)               18593887  \n",
            "=================================================================\n",
            "Total params: 18,593,887\n",
            "Trainable params: 919,040\n",
            "Non-trainable params: 17,674,847\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NenF1UR6b9Tf"
      },
      "source": [
        "embeds = []\n",
        "for images, labels in tqdm(val_ds):\n",
        "      embeds.append(reconstructed_model.predict(images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mFWRGQvcL77"
      },
      "source": [
        "image_embeddings = np.concatenate(embeds)\n",
        "test_df_pred, image_predictions = get_image_neighbors(test_df, image_embeddings, KNN = 50) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs43XqFRnoB9"
      },
      "source": [
        "def get_text_predictions(df, max_features=25000):\n",
        "    \n",
        "    model = TfidfVectorizer(stop_words='english', binary=True, max_features=max_features)\n",
        "    text_embeddings = model.fit_transform(df['title']).toarray()\n",
        "\n",
        "    print('Finding similar titles...')\n",
        "    CHUNK = 1024 * 4\n",
        "    CTS = len(df) // CHUNK\n",
        "    if (len(df)%CHUNK) != 0:\n",
        "        CTS += 1\n",
        "\n",
        "    preds = []\n",
        "    for j in range( CTS ):\n",
        "        a = j * CHUNK\n",
        "        b = (j+1) * CHUNK\n",
        "        b = min(b, len(df))\n",
        "        print('chunk', a, 'to', b)\n",
        "\n",
        "        # COSINE SIMILARITY DISTANCE\n",
        "        cts = np.matmul(text_embeddings, text_embeddings[a:b].T).T\n",
        "        for k in range(b-a):\n",
        "            IDX = np.where(cts[k,]>0.75)[0]\n",
        "            o = df.iloc[np.asarray(IDX)].posting_id.values\n",
        "            preds.append(o)\n",
        "\n",
        "    del model,text_embeddings\n",
        "    gc.collect()\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-ygZ1o5nyLS"
      },
      "source": [
        "text_predictions = get_text_predictions(test_df, max_features=25000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrBw0SFnp-yZ"
      },
      "source": [
        "len(text_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb7TezdxoTCx"
      },
      "source": [
        "def combine_predictions(row):\n",
        "    x = np.concatenate([row['image_predictions'], row['text_predictions']])\n",
        "    return ' '.join( np.unique(x) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "045XHZ0ynnZ1"
      },
      "source": [
        "test_df_pred['image_predictions'] = image_predictions\n",
        "test_df_pred['text_predictions'] = text_predictions\n",
        "test_df_pred['matches'] = test_df_pred.apply(combine_predictions, axis=1)\n",
        "test_df_pred[['posting_id', 'matches']].to_csv('/content/drive/MyDrive/shopee/outputs/submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwngPcJgmWeS"
      },
      "source": [
        "test_df_pred = pd.read_csv('/content/drive/MyDrive/shopee/outputs/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXv26uJ_Lq6z"
      },
      "source": [
        "test_df_pred.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OxIglaULtXT"
      },
      "source": [
        "test_df_pred['f1'] = f1_score(test_df_pred['posting_id'], test_df_pred['matches'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwCTrHBzMG0_"
      },
      "source": [
        "test_df_pred['f1'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzXjcxc6MgPY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}