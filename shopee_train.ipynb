{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shopee_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS-vFFUPWHTi",
        "outputId": "471f3d73-286c-4923-aa86-b992ed691f4a"
      },
      "source": [
        "!nvidia-smi\n",
        "!fuser -v /dev/nvidia0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msEJC9ps8thh",
        "outputId": "9fdb3c31-e4ed-4675-b6e0-2154f3ade6e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj8wAa9bbFLt",
        "outputId": "4caaba50-d989-4c51-973e-0049fd0ca8cb"
      },
      "source": [
        "!kill -9 2432  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTSMPCo-eEnd",
        "outputId": "bc0c840f-d10e-4d55-8591-44d75464cce9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1bHHQpMs6_e",
        "outputId": "d64c4668-20c7-4e42-e772-76fa509e913e"
      },
      "source": [
        "!ls                                      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9qnx6noWopA",
        "outputId": "97facd9b-6a16-40b1-9606-9ccc2c7c696e"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "import albumentations\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02U43ruWYgkd"
      },
      "source": [
        "class CFG:\n",
        "    seed = 54\n",
        "    classes = 11014 \n",
        "    scale = 30 \n",
        "    margin = 0.5\n",
        "    fc_dim = 512\n",
        "    img_size = 380  #对应EfficientNetB4的输入分辨率 \n",
        "    batch_size = 8\n",
        "    channels = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IWqrKhhX69D"
      },
      "source": [
        "def read_dataset(csv_path, image_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    image_paths = image_path + df['image']\n",
        "    return df, image_paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr5dHl1aapxF"
      },
      "source": [
        "image_path = '/content/drive/MyDrive/shopee/shopee-product-matching/train_images/'\n",
        "csv_path = '/content/drive/MyDrive/shopee/shopee-product-matching/train_r.csv' # repalce the train.csv\n",
        "df, image_paths = read_dataset(csv_path, image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnlUBUulLEFT"
      },
      "source": [
        "# # The pictures pulled out by kaggle are not complete, so you need to delete related non-existent paths\n",
        "# df['isexist'] = df.apply(lambda x: 1 if os.path.isfile(image_path + x['image']) else 0, axis = 1)\n",
        "# df = df[df['isexist'] == 1]\n",
        "# df.drop(columns = ['isexist'], inplace=True)\n",
        "# df.to_csv('/content/drive/MyDrive/shopee/shopee-product-matching/train_r.csv', sep = ',', index_col=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ktBubcAdZGxy",
        "outputId": "6d5f470f-b396-4284-bdc2-022000609aaa"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R87o28q-YaKD"
      },
      "source": [
        "label2id = dict(zip(range(df.label_group.nunique()),df.label_group.unique()))\n",
        "id2label = dict(zip(df.label_group.unique(),range(df.label_group.nunique())))\n",
        "df[\"labels\"] = df[\"label_group\"].map(id2label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5jfpk8I_Z3D1",
        "outputId": "3040c5c1-a6ad-4550-f2a7-15c5f947ddae"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG7ygTY6cNHB"
      },
      "source": [
        "# train_df, test_df = train_test_split(df, test_size = 0.1)\n",
        "# train_image_paths, test_image_paths = train_test_split(image_paths, test_size = 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759wmyPtasMv"
      },
      "source": [
        "def f1_score(y_true, y_pred):\n",
        "    y_true = y_true.apply(lambda x: set(x.split()))\n",
        "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
        "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
        "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
        "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
        "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
        "    return f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIxP88Qfmdyn"
      },
      "source": [
        "def get_image_neighbors(df, embeddings, KNN=50):\n",
        "\n",
        "    model = NearestNeighbors(n_neighbors = KNN)\n",
        "    model.fit(embeddings)\n",
        "    distances, indices = model.kneighbors(embeddings)\n",
        "    \n",
        "    threshold = 4.5\n",
        "    predictions = []\n",
        "    for k in tqdm(range(embeddings.shape[0])):\n",
        "        idx = np.where(distances[k,] < threshold)[0]\n",
        "        ids = indices[k,idx]\n",
        "        posting_ids = df['posting_id'].iloc[ids].values\n",
        "        predictions.append(posting_ids)\n",
        "        \n",
        "    del model, distances, indices\n",
        "    gc.collect()\n",
        "    return df, predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_pSb21obyjU"
      },
      "source": [
        "def data_augment(image, label):\n",
        "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "            \n",
        "    # Flips\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    if p_spatial > .75:\n",
        "        image = tf.image.transpose(image)\n",
        "        \n",
        "    # Rotates\n",
        "    if p_rotate > .75:\n",
        "        image = tf.image.rot90(image, k=3) \n",
        "    elif p_rotate > .5:\n",
        "        image = tf.image.rot90(image, k=2) \n",
        "    elif p_rotate > .25:\n",
        "        image = tf.image.rot90(image, k=1) \n",
        "        \n",
        "    \n",
        "    if p_pixel_1 >= .4:\n",
        "        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
        "    if p_pixel_2 >= .4:\n",
        "        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n",
        "    if p_pixel_3 >= .4:\n",
        "        image = tf.image.random_brightness(image, max_delta=.1)\n",
        "        \n",
        "    \n",
        "    if p_crop > .7:\n",
        "        if p_crop > .9:\n",
        "            image = tf.image.central_crop(image, central_fraction=.7)\n",
        "        elif p_crop > .8:\n",
        "            image = tf.image.central_crop(image, central_fraction=.8)\n",
        "        else:\n",
        "            image = tf.image.central_crop(image, central_fraction=.9)\n",
        "    elif p_crop > .4:\n",
        "        crop_size = tf.random.uniform([], int(CFG.img_size*.8), CFG.img_size, dtype=tf.int32)\n",
        "        image = tf.image.random_crop(image, size=[crop_size, crop_size, CFG.channels])\n",
        "    \n",
        "    image = tf.image.resize(image, [CFG.img_size, CFG.img_size])\n",
        "    return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHJYIJddbYD1"
      },
      "source": [
        "# Function to decode our images\n",
        "def preprocess_image(image):\n",
        "    \n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)  # / 255.0  # normalize to [0,1], but effnet has normlayer\n",
        "    image = tf.image.resize(image, [CFG.img_size, CFG.img_size])\n",
        "    return image\n",
        "\n",
        "# Function to read our test image and return image\n",
        "def load_and_preprocess_image(image, label):\n",
        "    image = tf.io.read_file(image)\n",
        "    image = preprocess_image(image)\n",
        "    return image, label\n",
        "\n",
        "def get_dataset(image, label):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image, label))\n",
        "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls = AUTO) \n",
        "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO) # data_augment\n",
        "    return dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARGZL5cDdmUM"
      },
      "source": [
        "SPLIT = int(0.8*len(df))\n",
        "# 1. datasets\n",
        "dataset = get_dataset(image_paths, df.labels)\n",
        "train_ds = dataset.take(SPLIT)\n",
        "val_ds = dataset.skip(SPLIT)\n",
        "\n",
        "# split the datasets\n",
        "train_df = df.iloc[:SPLIT, :]\n",
        "val_df = df.iloc[SPLIT:, :]\n",
        "\n",
        "train_ds = train_ds.cache().repeat().shuffle(CFG.batch_size*20).batch(CFG.batch_size).prefetch(AUTO)\n",
        "val_ds = val_ds.cache().batch(CFG.batch_size).prefetch(AUTO) # no shuffle on test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9EzDJR4ghXO"
      },
      "source": [
        "# Arcmarginproduct class keras layer\n",
        "class ArcMarginProduct(tf.keras.layers.Layer):\n",
        "    '''\n",
        "    Implements large margin arc distance.\n",
        "\n",
        "    Reference:\n",
        "        https://arxiv.org/pdf/1801.07698.pdf\n",
        "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
        "            blob/master/src/modeling/metric_learning.py\n",
        "    '''\n",
        "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
        "                 ls_eps=0.0, **kwargs):\n",
        "\n",
        "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.ls_eps = ls_eps\n",
        "        self.easy_margin = easy_margin\n",
        "        self.cos_m = tf.math.cos(m)\n",
        "        self.sin_m = tf.math.sin(m)\n",
        "        self.th = tf.math.cos(math.pi - m)\n",
        "        self.mm = tf.math.sin(math.pi - m) * m\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'n_classes': self.n_classes,\n",
        "            's': self.s,\n",
        "            'm': self.m,\n",
        "            'ls_eps': self.ls_eps,\n",
        "            'easy_margin': self.easy_margin,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(ArcMarginProduct, self).build(input_shape[0])\n",
        "\n",
        "        self.W = self.add_weight(\n",
        "            name='W',\n",
        "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
        "            initializer='glorot_uniform',\n",
        "            dtype='float32',\n",
        "            trainable=True,\n",
        "            regularizer=None)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        X, y = inputs\n",
        "        y = tf.cast(y, dtype=tf.int32)\n",
        "        cosine = tf.matmul(\n",
        "            tf.math.l2_normalize(X, axis=1),\n",
        "            tf.math.l2_normalize(self.W, axis=0)\n",
        "        )\n",
        "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if self.easy_margin:\n",
        "            phi = tf.where(cosine > 0, phi, cosine)\n",
        "        else:\n",
        "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        one_hot = tf.cast(\n",
        "            tf.one_hot(y, depth=self.n_classes),\n",
        "            dtype=cosine.dtype\n",
        "        )\n",
        "        if self.ls_eps > 0:\n",
        "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
        "\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        output *= self.s\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjO76NHTgbE2"
      },
      "source": [
        "\n",
        "class EffModel(Model):\n",
        "    def __init__(self, n_classes = CFG.classes,\n",
        "        img_size = CFG.img_size,\n",
        "        fc_dim = CFG.fc_dim\n",
        "        ):\n",
        "        super(EffModel, self).__init__()\n",
        "        \n",
        "        inputs = layers.Input(shape=(img_size, img_size, 3))\n",
        "        #inputs = albumentations(inputs)\n",
        "        self.backbone = EfficientNetB4(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
        "        \n",
        "        # Freeze the pretrained weights\n",
        "        self.backbone.trainable = False\n",
        "        \n",
        "        self.pooling = layers.GlobalAveragePooling2D(name=\"avg_pool\")\n",
        "        self.flatten = layers.Flatten()\n",
        "        \n",
        "        # Rebuild top\n",
        "        self.dropout = layers.Dropout(rate = 0.1, name=\"dropout\")\n",
        "        self.classifier = layers.Dense(fc_dim, activation=\"relu\", name=\"pred\") # rule\n",
        "        self.bn = layers.BatchNormalization()      \n",
        "\n",
        "    def call(self, inputs):\n",
        "        features = self.extract_features(inputs) \n",
        "        return features\n",
        "    \n",
        "    def extract_features(self, x):\n",
        "        # effnet + pooling + fc\n",
        "        x = self.backbone(x)\n",
        "        x = self.pooling(x)   \n",
        "        x = self.flatten(x) \n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = self.classifier(x)\n",
        "        x = self.bn(x)\n",
        "            \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBm3NIWsRF71"
      },
      "source": [
        "\n",
        "def create_model():\n",
        "\n",
        "    backbone = EffModel()\n",
        "\n",
        "    margin = ArcMarginProduct(n_classes = CFG.classes, \n",
        "                  s = 30, \n",
        "                  m = 0.5, \n",
        "                  name='head/arc_margin', \n",
        "                  dtype='float32'\n",
        "                  )\n",
        "\n",
        "    image = tf.keras.layers.Input(shape=(CFG.img_size, CFG.img_size, 3), name='input/image')\n",
        "    label = tf.keras.layers.Input((), name='input/label')\n",
        "\n",
        "    x = backbone(image) \n",
        "    x = margin([x, label]) # Archead\n",
        "\n",
        "    model = tf.keras.models.Model(inputs = [image, label], outputs = x)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw8x3AEzfPbn",
        "outputId": "ee9441a5-a5af-44a8-e710-06eda0ead13e"
      },
      "source": [
        "# 2. create_model\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TjS89MmfUMV"
      },
      "source": [
        "# 3. loss and test\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "mean_accuracy_train = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBY3JX-tfeZF"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMXN4w8QCiw_"
      },
      "source": [
        "# Save the model, because colab will crash at any time\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer = optimizer, model = model)\n",
        "\n",
        "manager = tf.train.CheckpointManager(ckpt, '/content/drive/MyDrive/shopee/my_model', max_to_keep=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyWr8pvqbiD6"
      },
      "source": [
        "# 手动保存权重\n",
        "\n",
        "def training_model():\n",
        "  \n",
        "    Epochs = 50\n",
        "    ckpt.restore(manager.latest_checkpoint)\n",
        "\n",
        "    if manager.latest_checkpoint:\n",
        "      print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "    else:\n",
        "      print(\"Initializing from scratch.\")\n",
        "\n",
        "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "    train_acc = tf.keras.metrics.Mean(name='train_acc')\n",
        "    test_acc = tf.keras.metrics.Mean(name='test_acc')\n",
        " \n",
        "    def train_step(images, labels):\n",
        "        with tf.GradientTape() as tape:\n",
        "            probs = model([images, labels], training = True)\n",
        "            loss = loss_object(labels, probs)\n",
        "            acc = mean_accuracy_train(labels, probs)\n",
        "\n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        " \n",
        "        train_loss(loss)\n",
        "        train_acc(acc)\n",
        " \n",
        "    def test_step(images, labels):\n",
        "        probs = model([images, labels], training = False)\n",
        "        loss = loss_object(labels, probs)\n",
        "        acc = mean_accuracy_train(labels, probs)\n",
        "\n",
        "        test_loss(loss)\n",
        "        test_acc(acc)\n",
        " \n",
        "    for epoch in tqdm(range(Epochs)):\n",
        "\n",
        "        train_loss.reset_states()\n",
        "        test_loss.reset_states()\n",
        "\n",
        "        train_acc.reset_states()\n",
        "        test_acc.reset_states()\n",
        "\n",
        "\n",
        "        for images, labels in train_ds:\n",
        "            train_step(images, labels)\n",
        "\n",
        "            ckpt.step.assign_add(1) \n",
        "            if int(ckpt.step) % 100 == 0:\n",
        "              p_out = 'loss: {}, acc: {}'\n",
        "              print(p_out.format(train_loss.result().numpy(), train_acc.result().numpy()))\n",
        "\n",
        "            if int(ckpt.step) % 500 == 0:\n",
        "              save_path = manager.save()\n",
        "              print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
        "        \n",
        "        for images, labels in val_ds:\n",
        "            test_step(images, labels)\n",
        " \n",
        "        tmp = 'Epoch: {}, train_loss: {}, test_loss: {}, train_acc: {}, test_acc: {}'\n",
        "        print(tmp.format(epoch+1, train_loss.result(), test_loss.result(),train_acc.result(), test_acc.result()))\n",
        "\n",
        "        \n",
        "    return model\n",
        "\n",
        "model = training_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXeAMd05TiRJ"
      },
      "source": [
        "saved_model_path = \"/content/drive/MyDrive/shopee/my_model/\"\n",
        "model.save_weights(saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf9nUdwajlRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "746e7fd0-654f-4d0e-cb51-c55bee3442fb"
      },
      "source": [
        "reconstructed_model = create_model()\n",
        "reconstructed_model.load_weights(saved_model_path)\n",
        "# 重新取输入和输出 选取embedding层作为输出\n",
        "reconstructed_model = tf.keras.models.Model(inputs = reconstructed_model.input[0], outputs = reconstructed_model.layers[-3].output) \n",
        "reconstructed_model.build((None, 380, 380, 3))\n",
        "reconstructed_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NenF1UR6b9Tf"
      },
      "source": [
        "embeds = []\n",
        "for images, labels in tqdm(val_ds):\n",
        "      embeds.append(reconstructed_model.predict(images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mFWRGQvcL77"
      },
      "source": [
        "image_embeddings = np.concatenate(embeds)\n",
        "val_df_pred, image_predictions = get_image_neighbors(val_df, image_embeddings, KNN = 50)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs43XqFRnoB9"
      },
      "source": [
        "def get_text_predictions(df, max_features=25000):\n",
        "    \n",
        "    model = TfidfVectorizer(stop_words='english', binary=True, max_features=max_features)\n",
        "    text_embeddings = model.fit_transform(df['title']).toarray()\n",
        "\n",
        "    print('Finding similar titles...')\n",
        "    CHUNK = 1024 * 4\n",
        "    CTS = len(df) // CHUNK\n",
        "    if (len(df)%CHUNK) != 0:\n",
        "        CTS += 1\n",
        "\n",
        "    preds = []\n",
        "    for j in range( CTS ):\n",
        "        a = j * CHUNK\n",
        "        b = (j+1) * CHUNK\n",
        "        b = min(b, len(df))\n",
        "        print('chunk', a, 'to', b)\n",
        "\n",
        "        # COSINE SIMILARITY DISTANCE\n",
        "        cts = np.matmul(text_embeddings, text_embeddings[a:b].T).T\n",
        "        for k in range(b-a):\n",
        "            IDX = np.where(cts[k,]>0.75)[0]\n",
        "            o = df.iloc[np.asarray(IDX)].posting_id.values\n",
        "            preds.append(o)\n",
        "\n",
        "    del model,text_embeddings\n",
        "    gc.collect()\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-ygZ1o5nyLS"
      },
      "source": [
        "text_predictions = get_text_predictions(val_df, max_features=25000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrBw0SFnp-yZ"
      },
      "source": [
        "len(text_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb7TezdxoTCx"
      },
      "source": [
        "def combine_predictions(row):\n",
        "    x = np.concatenate([row['image_predictions'], row['text_predictions']])\n",
        "    return ' '.join( np.unique(x) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "045XHZ0ynnZ1"
      },
      "source": [
        "test_df_pred['image_predictions'] = image_predictions\n",
        "test_df_pred['text_predictions'] = text_predictions\n",
        "test_df_pred['matches'] = test_df_pred.apply(combine_predictions, axis=1)\n",
        "test_df_pred[['posting_id', 'matches']].to_csv('/content/drive/MyDrive/shopee/outputs/submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwngPcJgmWeS"
      },
      "source": [
        "test_df_pred = pd.read_csv('/content/drive/MyDrive/shopee/outputs/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXv26uJ_Lq6z"
      },
      "source": [
        "test_df_pred.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OxIglaULtXT"
      },
      "source": [
        "test_df_pred['f1'] = f1_score(test_df_pred['posting_id'], test_df_pred['matches'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwCTrHBzMG0_"
      },
      "source": [
        "test_df_pred['f1'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzXjcxc6MgPY"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}