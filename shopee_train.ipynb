{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "shopee_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS-vFFUPWHTi",
        "outputId": "283c43fe-3cbc-477a-8cae-9b5abc6135bb"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jul 12 13:53:00 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePsT3jTc40N2",
        "outputId": "6585c4b5-6a3c-408a-eb4b-5b032002f053"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9qnx6noWopA",
        "outputId": "df509639-381d-4c17-9db5-20cf8a592be4"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.applications import EfficientNetB4\n",
        "from tensorflow.keras import backend as K\n",
        "import albumentations\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02U43ruWYgkd"
      },
      "source": [
        "class CFG:\n",
        "    seed = 2021\n",
        "    Epochs = 60\n",
        "    classes = 11014 \n",
        "    scale = 30 \n",
        "    margin = 0.1\n",
        "    fc_dim = 512\n",
        "    img_size = 384  \n",
        "    batch_size = 16\n",
        "    channels = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IWqrKhhX69D"
      },
      "source": [
        "def read_dataset(csv_path, image_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    image_paths = image_path + df['image']\n",
        "    return df, image_paths"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr5dHl1aapxF"
      },
      "source": [
        "image_path = '/content/drive/MyDrive/shopee/shopee-product-matching/train_images/'\n",
        "csv_path = '/content/drive/MyDrive/shopee/shopee-product-matching/train.csv' # repalce the train.csv\n",
        "df, image_paths = read_dataset(csv_path, image_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktBubcAdZGxy",
        "outputId": "630f18c7-a92d-4e23-fb66-e9896a17d6bb"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34250, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R87o28q-YaKD",
        "outputId": "e1b7e51a-67a4-4056-e810-eb64d05b868a"
      },
      "source": [
        "labelencoder= LabelEncoder()\n",
        "df['label_group'] = labelencoder.fit_transform(df['label_group'])\n",
        "CFG.classes = df['label_group'].nunique()\n",
        "CFG.classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "5jfpk8I_Z3D1",
        "outputId": "9fde94a1-6c67-4b03-eab9-e9210dd78694"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posting_id</th>\n",
              "      <th>image</th>\n",
              "      <th>image_phash</th>\n",
              "      <th>title</th>\n",
              "      <th>label_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_129225211</td>\n",
              "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
              "      <td>94974f937d4c2433</td>\n",
              "      <td>Paper Bag Victoria Secret</td>\n",
              "      <td>666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_3386243561</td>\n",
              "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
              "      <td>af3f9460c2838f0f</td>\n",
              "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
              "      <td>7572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2288590299</td>\n",
              "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
              "      <td>b94cb00ed3e50f78</td>\n",
              "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
              "      <td>6172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_2406599165</td>\n",
              "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
              "      <td>8514fc58eafea283</td>\n",
              "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
              "      <td>10509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_3369186413</td>\n",
              "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
              "      <td>a6f319f924ad708c</td>\n",
              "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
              "      <td>9425</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         posting_id  ... label_group\n",
              "0   train_129225211  ...         666\n",
              "1  train_3386243561  ...        7572\n",
              "2  train_2288590299  ...        6172\n",
              "3  train_2406599165  ...       10509\n",
              "4  train_3369186413  ...        9425\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759wmyPtasMv"
      },
      "source": [
        "def f1_score(y_true, y_pred):\n",
        "  y_true = y_true.apply(lambda x: set(x.split()))\n",
        "  y_pred = y_pred.apply(lambda x: set(x.split()))\n",
        "  intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
        "  len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
        "  len_y_true = y_true.apply(lambda x: len(x)).values\n",
        "  f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
        "  return f1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "kIxP88Qfmdyn"
      },
      "source": [
        "def get_image_neighbors(df, embeddings, KNN=50, threshold = 4.5):\n",
        "\n",
        "    model = NearestNeighbors(n_neighbors = KNN)\n",
        "    model.fit(embeddings)\n",
        "    distances, indices = model.kneighbors(embeddings)\n",
        "    \n",
        "    predictions = []\n",
        "    for k in tqdm(range(embeddings.shape[0])):\n",
        "        idx = np.where(distances[k,] < threshold)[0]\n",
        "        ids = indices[k,idx]\n",
        "        posting_ids = df['posting_id'].iloc[ids].values\n",
        "        predictions.append(posting_ids)\n",
        "        \n",
        "    del model, distances, indices\n",
        "    gc.collect()\n",
        "    return df, predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "g_pSb21obyjU"
      },
      "source": [
        "# data_augment\n",
        "def data_augment(image, label):\n",
        "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "            \n",
        "    # Flips\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    if p_spatial > .75:\n",
        "        image = tf.image.transpose(image)\n",
        "        \n",
        "    # Rotates\n",
        "    if p_rotate > .75:\n",
        "        image = tf.image.rot90(image, k=3) \n",
        "    elif p_rotate > .5:\n",
        "        image = tf.image.rot90(image, k=2) \n",
        "    elif p_rotate > .25:\n",
        "        image = tf.image.rot90(image, k=1) \n",
        "        \n",
        "    \n",
        "    if p_pixel_1 >= .4:\n",
        "        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
        "    if p_pixel_2 >= .4:\n",
        "        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n",
        "    if p_pixel_3 >= .4:\n",
        "        image = tf.image.random_brightness(image, max_delta=.1)\n",
        "        \n",
        "    \n",
        "    if p_crop > .7:\n",
        "        if p_crop > .9:\n",
        "            image = tf.image.central_crop(image, central_fraction=.7)\n",
        "        elif p_crop > .8:\n",
        "            image = tf.image.central_crop(image, central_fraction=.8)\n",
        "        else:\n",
        "            image = tf.image.central_crop(image, central_fraction=.9)\n",
        "    elif p_crop > .4:\n",
        "        crop_size = tf.random.uniform([], int(CFG.img_size*.8), CFG.img_size, dtype=tf.int32)\n",
        "        image = tf.image.random_crop(image, size=[crop_size, crop_size, CFG.channels])\n",
        "    \n",
        "    image = tf.image.resize(image, [CFG.img_size, CFG.img_size])\n",
        "    return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHJYIJddbYD1"
      },
      "source": [
        "# Function to decode our images\n",
        "def preprocess_image(image):\n",
        "    \n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)  # / 255.0  # normalize to [0,1], but effnet has normlayer\n",
        "    image = tf.image.resize(image, (CFG.img_size, CFG.img_size))\n",
        "    # image = tf.cast(image, tf.float32)\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_image(image, label_group):\n",
        "    image = tf.io.read_file(image)\n",
        "    image = preprocess_image(image)\n",
        "    return image,label_group\n",
        "\n",
        "def get_training_dataset(image, label_group):\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image, label_group))\n",
        "    dataset_label = tf.data.Dataset.from_tensor_slices(label_group)\n",
        "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls = AUTO)\n",
        "    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n",
        "    dataset = tf.data.Dataset.zip((dataset, dataset_label))\n",
        "\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(CFG.batch_size)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "\n",
        "# Function to get our validation dataset\n",
        "def get_validation_dataset(image, label_group):\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image, label_group))\n",
        "    dataset_label = tf.data.Dataset.from_tensor_slices(label_group)\n",
        "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls = AUTO)\n",
        "    dataset = tf.data.Dataset.zip((dataset, dataset_label))\n",
        "\n",
        "    dataset = dataset.batch(CFG.batch_size)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "\n",
        "def train_and_eval_split(image, label_group):\n",
        "    trn_image, val_image, trn_labels, val_labels = train_test_split(image, label_group, random_state = CFG.seed, shuffle = True)\n",
        "    return trn_image, val_image, trn_labels, val_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARGZL5cDdmUM"
      },
      "source": [
        "# split the datasets\n",
        "trn_image, val_image, trn_labels, val_labels = train_test_split(image_paths, df, random_state = CFG.seed, shuffle = True)\n",
        "train_dataset = get_training_dataset(trn_image, trn_labels['label_group'])\n",
        "val_dataset = get_validation_dataset(val_image, val_labels['label_group'])\n",
        "\n",
        "# train_ds = train_ds.cache(filename='./cache.tf-data').shuffle(buffer_size=1000).batch(CFG.batch_size).prefetch(AUTO) # cache会导致爆内存，当内存不够是使用文件进行缓存\n",
        "# val_ds = val_ds.cache(filename='./cache.val-data').batch(CFG.batch_size).prefetch(AUTO) # no shuffle on test prefetch 预取数据，maybe无需使用cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gadhTw_V8_VN",
        "outputId": "8d53c64f-3f22-4625-f935-bf8d0d690316"
      },
      "source": [
        "train_dataset.take(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: (((None, 384, 384, 3), (None,)), (None,)), types: ((tf.float32, tf.int64), tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "V9EzDJR4ghXO"
      },
      "source": [
        "class ArcMarginProduct(tf.keras.layers.Layer):\n",
        "    '''\n",
        "    Implements large margin arc distance.\n",
        "\n",
        "    Reference:\n",
        "        https://arxiv.org/pdf/1801.07698.pdf\n",
        "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
        "            blob/master/src/modeling/metric_learning.py\n",
        "    '''\n",
        "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
        "                 ls_eps=0.0, **kwargs):\n",
        "\n",
        "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.ls_eps = ls_eps\n",
        "        self.easy_margin = easy_margin\n",
        "        self.cos_m = tf.math.cos(m)\n",
        "        self.sin_m = tf.math.sin(m)\n",
        "        self.th = tf.math.cos(math.pi - m)\n",
        "        self.mm = tf.math.sin(math.pi - m) * m\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(ArcMarginProduct, self).build(input_shape[0])\n",
        "\n",
        "        self.W = self.add_weight(\n",
        "            name='W',\n",
        "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
        "            initializer='glorot_uniform',\n",
        "            dtype='float32',\n",
        "            trainable=True,\n",
        "            regularizer=None)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        X, y = inputs\n",
        "        y = tf.cast(y, dtype=tf.int32)\n",
        "        cosine = tf.matmul(\n",
        "            tf.math.l2_normalize(X, axis=1),\n",
        "            tf.math.l2_normalize(self.W, axis=0)\n",
        "        )\n",
        "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if self.easy_margin:\n",
        "            phi = tf.where(cosine > 0, phi, cosine)\n",
        "        else:\n",
        "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        one_hot = tf.cast(\n",
        "            tf.one_hot(y, depth=self.n_classes),\n",
        "            dtype=cosine.dtype\n",
        "        )\n",
        "        if self.ls_eps > 0:\n",
        "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
        "\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        output *= self.s\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBm3NIWsRF71"
      },
      "source": [
        "def create_model():\n",
        "\n",
        "  margin = ArcMarginProduct(n_classes = CFG.classes, s = 30, m = 0.5, \n",
        "                name = 'head/arc_margin', dtype = 'float32')\n",
        "\n",
        "  image = tf.keras.layers.Input(shape=(CFG.img_size, CFG.img_size, 3), name='input/image')\n",
        "  label = tf.keras.layers.Input((), name='input/label')\n",
        "\n",
        "  x = EfficientNetB4(include_top = False, weights = 'imagenet')(image)\n",
        "  x = tf.keras.layers.GlobalAveragePooling2D(name='head/pooling')(x)\n",
        "  \n",
        "  x = tf.keras.layers.BatchNormalization(name='head/bn1')(x)\n",
        "  x = tf.keras.layers.Dropout(rate = 0.5, name='head/dropout')(x)\n",
        "  x = tf.keras.layers.Dense(CFG.fc_dim,name='head/dense')(x)\n",
        "  x = tf.keras.layers.BatchNormalization(name='head/bn2')(x)\n",
        "\n",
        "  x = margin([x, label]) # Archead\n",
        "  output = tf.keras.layers.Softmax()(x)\n",
        "\n",
        "  model = tf.keras.models.Model(inputs = [image, label], outputs = output)\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
        "\n",
        "  model.compile(\n",
        "        optimizer = opt,\n",
        "        loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n",
        "        metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "    )\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lw8x3AEzfPbn",
        "outputId": "32287edd-0f8a-4b5f-fb1a-27e8e1a02dd3"
      },
      "source": [
        "# 2. create_model\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
            "71688192/71686520 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input/image (InputLayer)        [(None, 384, 384, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "efficientnetb4 (Functional)     (None, None, None, 1 17673823    input/image[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "head/pooling (GlobalAveragePool (None, 1792)         0           efficientnetb4[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "head/bn1 (BatchNormalization)   (None, 1792)         7168        head/pooling[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "head/dropout (Dropout)          (None, 1792)         0           head/bn1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "head/dense (Dense)              (None, 512)          918016      head/dropout[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "head/bn2 (BatchNormalization)   (None, 512)          2048        head/dense[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "input/label (InputLayer)        [(None,)]            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "head/arc_margin (ArcMarginProdu (None, 11014)        5639168     head/bn2[0][0]                   \n",
            "                                                                 input/label[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Softmax)               (None, 11014)        0           head/arc_margin[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 24,240,223\n",
            "Trainable params: 24,110,408\n",
            "Non-trainable params: 129,815\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8YmoFZs5kxu"
      },
      "source": [
        "# Function to seed everything\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    tf.random.set_seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsqC3iZABoJ_"
      },
      "source": [
        "class CustomCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, checkpoint, manager, saved_model_path):\n",
        "        super(CustomCallback, self).__init__()\n",
        "        # load and save model \n",
        "        self.checkpoint = checkpoint\n",
        "        self.manager = manager\n",
        "        self.saved_model_path = saved_model_path\n",
        "\n",
        "        # uodate learning rate\n",
        "        self.lr_start = 0.000001\n",
        "        self.lr_max = 0.000005 * CFG.batch_size\n",
        "        self.lr_min = 0.000001\n",
        "        self.lr_ramp_ep = 5\n",
        "        self.lr_sus_ep = 0\n",
        "        self.lr_decay = 0.8\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.checkpoint.restore(self.manager.latest_checkpoint) # 训练开始是加载模型\n",
        "        if self.manager.latest_checkpoint:\n",
        "          print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "        else:\n",
        "          print(\"Initializing from scratch.\")\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        self.model.save_weights(self.saved_model_path)\n",
        "        print('Save the model weights on end {}'.format(self.saved_model_path))\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        # update learning rate\n",
        "        scheduled_lr = self.lrfn(epoch)\n",
        "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
        "        print(\"\\nEpoch %05d: Learning rate is %6.6f.\" % (epoch, scheduled_lr))\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.manager.save() # 每个epoch保存模型\n",
        "        print('Save model on epoch {}'.format(epoch))\n",
        "\n",
        "    def lrfn(self, epoch):\n",
        "        # learning rate warmup\n",
        "        if epoch < self.lr_ramp_ep:\n",
        "            lr = (self.lr_max - self.lr_start) / self.lr_ramp_ep * epoch + self.lr_start   \n",
        "        elif epoch < self.lr_ramp_ep + self.lr_sus_ep:\n",
        "            lr = self.lr_max    \n",
        "        else:\n",
        "            lr = (self.lr_max - self.lr_min) * self.lr_decay**(epoch - self.lr_ramp_ep - self.lr_sus_ep) + self.lr_min    \n",
        "        return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmsrkSKGqYi_"
      },
      "source": [
        "saved_model_path = '/content/drive/MyDrive/shopee/my_model/effnetb4_arc.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8y3pAhtvkmp"
      },
      "source": [
        "checkpoint = tf.train.Checkpoint(optimizer = model.optimizer, model = model) # 保存和加载模型\n",
        "manager = tf.train.CheckpointManager(checkpoint, directory = \"/content/drive/MyDrive/shopee/my_model/model/\", max_to_keep = 3)\n",
        "custom_cb = CustomCallback(checkpoint, manager, saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HonVshGY5oEB"
      },
      "source": [
        "def training_model():\n",
        "\n",
        "    print('\\n')\n",
        "    print('-'*50)\n",
        "    # Seed everything\n",
        "    seed_everything(CFG.seed)\n",
        "\n",
        "    STEPS_PER_EPOCH = len(image_paths) // CFG.batch_size\n",
        "    initial_epoch = int(manager.latest_checkpoint.split('-')[1])\n",
        "    \n",
        "    K.clear_session()\n",
        "    \n",
        "    history = model.fit(train_dataset, steps_per_epoch = STEPS_PER_EPOCH,\n",
        "                epochs = 20, callbacks = [custom_cb], \n",
        "                validation_data = val_dataset, initial_epoch = initial_epoch, \n",
        "                verbose = 1)\n",
        "    print('\\n')\n",
        "    print('-'*50)\n",
        "    print('Training Complete...')\n",
        "    \n",
        "    return model\n",
        "# model = training_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf9nUdwajlRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5d0f6b0-1c1f-477d-a81a-b4a3bfb4a7d2"
      },
      "source": [
        "reconstructed_model = create_model()\n",
        "reconstructed_model.load_weights(saved_model_path)\n",
        "# 重新取输入和输出 选取embedding层作为输出\n",
        "reconstructed_model = tf.keras.models.Model(inputs = reconstructed_model.input[0], outputs = reconstructed_model.layers[-4].output) \n",
        "reconstructed_model.build((None, CFG.img_size, CFG.img_size, 3))\n",
        "reconstructed_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input/image (InputLayer)     [(None, 384, 384, 3)]     0         \n",
            "_________________________________________________________________\n",
            "efficientnetb4 (Functional)  (None, None, None, 1792)  17673823  \n",
            "_________________________________________________________________\n",
            "head/pooling (GlobalAverageP (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "head/bn1 (BatchNormalization (None, 1792)              7168      \n",
            "_________________________________________________________________\n",
            "head/dropout (Dropout)       (None, 1792)              0         \n",
            "_________________________________________________________________\n",
            "head/dense (Dense)           (None, 512)               918016    \n",
            "_________________________________________________________________\n",
            "head/bn2 (BatchNormalization (None, 512)               2048      \n",
            "=================================================================\n",
            "Total params: 18,601,055\n",
            "Trainable params: 18,471,240\n",
            "Non-trainable params: 129,815\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NenF1UR6b9Tf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff0918a-e3e1-4cf6-8b25-9aaa0e0bc44f"
      },
      "source": [
        "embeds = []\n",
        "for images, labels in tqdm(val_dataset):\n",
        "  #print(images[1].shape)\n",
        "  embeds.append(reconstructed_model.predict(images[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 536/536 [01:51<00:00,  4.81it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mFWRGQvcL77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26d78979-d13e-488a-f740-5900c94253f4"
      },
      "source": [
        "image_embeddings = np.concatenate(embeds)\n",
        "test_df_pred, image_predictions = get_image_neighbors(val_labels, image_embeddings, KNN = 50, threshold = 3.6) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8563/8563 [00:01<00:00, 7503.42it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEoOVYVqNGGm",
        "outputId": "1e510a5d-2487-4182-9903-811126ae1f5d"
      },
      "source": [
        "image_embeddings.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8563, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxA_lwwSgzeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1b4e8d-bb11-4693-a650-4583ad12222c"
      },
      "source": [
        "image_predictions[4].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEIUx-fEhBH5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de51375-70e2-419a-fecd-0526c4646728"
      },
      "source": [
        "len(image_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8563"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs43XqFRnoB9"
      },
      "source": [
        "def get_text_predictions(df, max_features=25000):\n",
        "    \n",
        "    model = TfidfVectorizer(stop_words='english', binary=True, max_features=max_features)\n",
        "    text_embeddings = model.fit_transform(df['title']).toarray()\n",
        "\n",
        "    print('Finding similar titles...')\n",
        "    CHUNK = 1024 * 4\n",
        "    CTS = len(df) // CHUNK\n",
        "    if (len(df)%CHUNK) != 0:\n",
        "        CTS += 1\n",
        "\n",
        "    preds = []\n",
        "    for j in range( CTS ):\n",
        "        a = j * CHUNK\n",
        "        b = (j+1) * CHUNK\n",
        "        b = min(b, len(df))\n",
        "        print('chunk', a, 'to', b)\n",
        "\n",
        "        # COSINE SIMILARITY DISTANCE\n",
        "        cts = np.matmul(text_embeddings, text_embeddings[a:b].T).T\n",
        "        for k in range(b-a):\n",
        "            IDX = np.where(cts[k,]>0.75)[0]\n",
        "            o = df.iloc[np.asarray(IDX)].posting_id.values\n",
        "            preds.append(o)\n",
        "\n",
        "    del model,text_embeddings\n",
        "    gc.collect()\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-ygZ1o5nyLS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb87616-7cfa-4441-f05c-beb5a0e99b71"
      },
      "source": [
        "text_predictions = get_text_predictions(val_labels, max_features=25000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finding similar titles...\n",
            "chunk 0 to 4096\n",
            "chunk 4096 to 8192\n",
            "chunk 8192 to 8563\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb7TezdxoTCx"
      },
      "source": [
        "def combine_predictions(row):\n",
        "  x = np.concatenate([row['image_predictions'], row['text_predictions']])\n",
        "  #x = row['image_predictions']\n",
        "  return ' '.join(np.unique(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "045XHZ0ynnZ1"
      },
      "source": [
        "test_df_pred['image_predictions'] = image_predictions\n",
        "test_df_pred['text_predictions'] = text_predictions\n",
        "test_df_pred['matches'] = test_df_pred.apply(combine_predictions, axis=1)\n",
        "test_df_pred[['posting_id', 'matches']].to_csv('/content/drive/MyDrive/shopee/submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51Ti4OAzlOi3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "12657191-d89a-4d4c-e6e6-5146262cf811"
      },
      "source": [
        "test_df_pred.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posting_id</th>\n",
              "      <th>matches</th>\n",
              "      <th>f1</th>\n",
              "      <th>image_predictions</th>\n",
              "      <th>text_predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_290863952</td>\n",
              "      <td>train_290863952</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[train_290863952]</td>\n",
              "      <td>[train_290863952]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_2543555082</td>\n",
              "      <td>train_2543555082 train_3013055580</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[train_2543555082]</td>\n",
              "      <td>[train_2543555082, train_3013055580]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_19057560</td>\n",
              "      <td>train_19057560</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[train_19057560]</td>\n",
              "      <td>[train_19057560]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3909851547</td>\n",
              "      <td>train_2640036529 train_3909851547 train_880041580</td>\n",
              "      <td>0.5</td>\n",
              "      <td>[train_3909851547, train_880041580, train_2640...</td>\n",
              "      <td>[train_3909851547]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_2578897315</td>\n",
              "      <td>train_2552330451 train_2578897315</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[train_2578897315]</td>\n",
              "      <td>[train_2578897315, train_2552330451]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         posting_id  ...                      text_predictions\n",
              "0   train_290863952  ...                     [train_290863952]\n",
              "1  train_2543555082  ...  [train_2543555082, train_3013055580]\n",
              "2    train_19057560  ...                      [train_19057560]\n",
              "3  train_3909851547  ...                    [train_3909851547]\n",
              "4  train_2578897315  ...  [train_2578897315, train_2552330451]\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwngPcJgmWeS"
      },
      "source": [
        "test_df_pred = pd.read_csv('/content/drive/MyDrive/shopee/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXv26uJ_Lq6z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "0ec5a29b-8088-4257-bc04-0fc60d5a32a3"
      },
      "source": [
        "test_df_pred.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posting_id</th>\n",
              "      <th>matches</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_290863952</td>\n",
              "      <td>train_290863952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_2543555082</td>\n",
              "      <td>train_2543555082 train_3013055580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_19057560</td>\n",
              "      <td>train_19057560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_3909851547</td>\n",
              "      <td>train_2640036529 train_3909851547 train_880041580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_2578897315</td>\n",
              "      <td>train_2552330451 train_2578897315</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         posting_id                                            matches\n",
              "0   train_290863952                                    train_290863952\n",
              "1  train_2543555082                  train_2543555082 train_3013055580\n",
              "2    train_19057560                                     train_19057560\n",
              "3  train_3909851547  train_2640036529 train_3909851547 train_880041580\n",
              "4  train_2578897315                  train_2552330451 train_2578897315"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OxIglaULtXT"
      },
      "source": [
        "test_df_pred['f1'] = f1_score(test_df_pred['posting_id'], test_df_pred['matches'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwCTrHBzMG0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7718c86-410b-4c16-bc3f-361f51471616"
      },
      "source": [
        "test_df_pred['f1'].mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.880404723800746"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R86hi_wqlkBK"
      },
      "source": [
        "text: 0.9624643874643882\n",
        "text+image: 0.5052306952306961\n",
        "image: 0.7310256410256404"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3ZgaIJWjytp"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}