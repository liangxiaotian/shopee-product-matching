{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shopee_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS-vFFUPWHTi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3550bf17-b00a-42cb-9dc0-9a8153f5e26d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun 26 23:34:14 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePsT3jTc40N2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1956698-bc1a-40d0-c5ee-b1d14b047b96"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSVkfHE3pKhb"
      },
      "source": [
        "!fuser -v /dev/nvidia0"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj8wAa9bbFLt",
        "outputId": "f07da8d8-53b5-4357-ce8e-66c219efccf1"
      },
      "source": [
        "!kill -9 2432  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: kill: (2432) - No such process\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1bHHQpMs6_e",
        "outputId": "263a30b9-73e6-4dd0-9b1a-5092205a818b"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9qnx6noWopA",
        "outputId": "ad657c78-ec25-4ec4-a51d-082382ca5027"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "import albumentations\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "AUTO = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02U43ruWYgkd"
      },
      "source": [
        "class CFG:\n",
        "    seed = 54\n",
        "    Epochs = 10\n",
        "    # classes = 11014 \n",
        "    scale = 30 \n",
        "    margin = 0.5\n",
        "    fc_dim = 512\n",
        "    img_size = 384  #对应EfficientNetB4的输入分辨率 \n",
        "    batch_size = 16\n",
        "    channels = 3"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IWqrKhhX69D"
      },
      "source": [
        "def read_dataset(csv_path, image_path):\n",
        "    df = pd.read_csv(csv_path)\n",
        "    image_paths = image_path + df['image']\n",
        "    return df, image_paths"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr5dHl1aapxF"
      },
      "source": [
        "image_path = '/content/drive/MyDrive/shopee/shopee-product-matching/train_images/'\n",
        "csv_path = '/content/drive/MyDrive/shopee/shopee-product-matching/train.csv' # repalce the train.csv\n",
        "df, image_paths = read_dataset(csv_path, image_path)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJ2-4rLFhlN_"
      },
      "source": [
        "# # The pictures pulled out by kaggle are not complete, so you need to delete related non-existent paths\n",
        "# df['isexist'] = df.apply(lambda x: 1 if os.path.isfile(image_path + x['image']) else 0, axis = 1)\n",
        "# df = df[df['isexist'] == 1]\n",
        "# df.drop(columns = ['isexist'], inplace=True)\n",
        "# df.to_csv('/content/drive/MyDrive/shopee/shopee-product-matching/train_r.csv', sep = ',', index=None)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktBubcAdZGxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd65c968-d149-4e9b-8296-b9ea602a354a"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(34250, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R87o28q-YaKD"
      },
      "source": [
        "labelencoder= LabelEncoder()\n",
        "df['label_group'] = labelencoder.fit_transform(df['label_group'])\n",
        "CFG.classes = df['label_group'].nunique()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzyOty3t5JHp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67473179-556f-4dcc-8614-6cf38fbcaf40"
      },
      "source": [
        "CFG.classes"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11014"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jfpk8I_Z3D1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "4c10eff8-24b2-4d0c-80b3-4bdd3fb6c4e2"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>posting_id</th>\n",
              "      <th>image</th>\n",
              "      <th>image_phash</th>\n",
              "      <th>title</th>\n",
              "      <th>label_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>train_129225211</td>\n",
              "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
              "      <td>94974f937d4c2433</td>\n",
              "      <td>Paper Bag Victoria Secret</td>\n",
              "      <td>666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>train_3386243561</td>\n",
              "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
              "      <td>af3f9460c2838f0f</td>\n",
              "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
              "      <td>7572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>train_2288590299</td>\n",
              "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
              "      <td>b94cb00ed3e50f78</td>\n",
              "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
              "      <td>6172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>train_2406599165</td>\n",
              "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
              "      <td>8514fc58eafea283</td>\n",
              "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
              "      <td>10509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>train_3369186413</td>\n",
              "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
              "      <td>a6f319f924ad708c</td>\n",
              "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
              "      <td>9425</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         posting_id  ... label_group\n",
              "0   train_129225211  ...         666\n",
              "1  train_3386243561  ...        7572\n",
              "2  train_2288590299  ...        6172\n",
              "3  train_2406599165  ...       10509\n",
              "4  train_3369186413  ...        9425\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG7ygTY6cNHB"
      },
      "source": [
        "# train_df, test_df = train_test_split(df, test_size = 0.1)\n",
        "# train_image_paths, test_image_paths = train_test_split(image_paths, test_size = 0.1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759wmyPtasMv"
      },
      "source": [
        "def f1_score(y_true, y_pred):\n",
        "    y_true = y_true.apply(lambda x: set(x.split()))\n",
        "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
        "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
        "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
        "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
        "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
        "    return f1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIxP88Qfmdyn",
        "cellView": "code"
      },
      "source": [
        "#@title\n",
        "def get_image_neighbors(df, embeddings, KNN=50):\n",
        "\n",
        "    model = NearestNeighbors(n_neighbors = KNN)\n",
        "    model.fit(embeddings)\n",
        "    distances, indices = model.kneighbors(embeddings)\n",
        "    \n",
        "    threshold = 4.5\n",
        "    predictions = []\n",
        "    for k in tqdm(range(embeddings.shape[0])):\n",
        "        idx = np.where(distances[k,] < threshold)[0]\n",
        "        ids = indices[k,idx]\n",
        "        posting_ids = df['posting_id'].iloc[ids].values\n",
        "        predictions.append(posting_ids)\n",
        "        \n",
        "    del model, distances, indices\n",
        "    gc.collect()\n",
        "    return df, predictions"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_pSb21obyjU",
        "cellView": "code"
      },
      "source": [
        "#@title\n",
        "def data_augment(image, label):\n",
        "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel_1 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel_2 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_pixel_3 = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
        "            \n",
        "    # Flips\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    if p_spatial > .75:\n",
        "        image = tf.image.transpose(image)\n",
        "        \n",
        "    # Rotates\n",
        "    if p_rotate > .75:\n",
        "        image = tf.image.rot90(image, k=3) \n",
        "    elif p_rotate > .5:\n",
        "        image = tf.image.rot90(image, k=2) \n",
        "    elif p_rotate > .25:\n",
        "        image = tf.image.rot90(image, k=1) \n",
        "        \n",
        "    \n",
        "    if p_pixel_1 >= .4:\n",
        "        image = tf.image.random_saturation(image, lower=.7, upper=1.3)\n",
        "    if p_pixel_2 >= .4:\n",
        "        image = tf.image.random_contrast(image, lower=.8, upper=1.2)\n",
        "    if p_pixel_3 >= .4:\n",
        "        image = tf.image.random_brightness(image, max_delta=.1)\n",
        "        \n",
        "    \n",
        "    if p_crop > .7:\n",
        "        if p_crop > .9:\n",
        "            image = tf.image.central_crop(image, central_fraction=.7)\n",
        "        elif p_crop > .8:\n",
        "            image = tf.image.central_crop(image, central_fraction=.8)\n",
        "        else:\n",
        "            image = tf.image.central_crop(image, central_fraction=.9)\n",
        "    elif p_crop > .4:\n",
        "        crop_size = tf.random.uniform([], int(CFG.img_size*.8), CFG.img_size, dtype=tf.int32)\n",
        "        image = tf.image.random_crop(image, size=[crop_size, crop_size, CFG.channels])\n",
        "    \n",
        "    image = tf.image.resize(image, [CFG.img_size, CFG.img_size])\n",
        "    return image, label"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHJYIJddbYD1"
      },
      "source": [
        "# Function to decode our images\n",
        "def preprocess_image(image):\n",
        "    \n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    #image = tf.image.convert_image_dtype(image, tf.float32)  # / 255.0  # normalize to [0,1], but effnet has normlayer\n",
        "    image = tf.image.resize(image, (CFG.img_size, CFG.img_size))\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_image(image, label_group):\n",
        "    image = tf.io.read_file(image)\n",
        "    image = preprocess_image(image)\n",
        "    return image, label_group\n",
        "\n",
        "def get_training_dataset(image, label_group):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image, label_group))\n",
        "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls = AUTO)\n",
        "    # dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(CFG.batch_size)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "\n",
        "# Function to get our validation dataset\n",
        "def get_validation_dataset(image, label_group):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((image, label_group))\n",
        "    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(CFG.batch_size)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        "\n",
        "def train_and_eval_split(image, label_group):\n",
        "    trn_image, val_image, trn_labels, val_labels = train_test_split(image, label_group, random_state = CFG.seed, shuffle = True)\n",
        "    return trn_image, val_image, trn_labels, val_labels\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARGZL5cDdmUM"
      },
      "source": [
        "trn_image, val_image, trn_labels, val_labels = train_test_split(image_paths, df['label_group'], random_state = CFG.seed, shuffle = True)\n",
        "train_dataset = get_training_dataset(trn_image, trn_labels)\n",
        "val_dataset = get_validation_dataset(val_image, val_labels)\n",
        "# split the datasets\n",
        "# train_ds = train_ds.cache(filename='./cache.tf-data').shuffle(buffer_size=1000).batch(CFG.batch_size).prefetch(AUTO) # cache会导致爆内存，当内存不够是使用文件进行缓存\n",
        "# val_ds = val_ds.cache(filename='./cache.val-data').batch(CFG.batch_size).prefetch(AUTO) # no shuffle on test prefetch 预取数据，maybe无需使用cache"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "V9EzDJR4ghXO"
      },
      "source": [
        "#@title\n",
        "# Arcmarginproduct class keras layer\n",
        "class ArcMarginProduct(tf.keras.layers.Layer):\n",
        "    '''\n",
        "    Implements large margin arc distance.\n",
        "\n",
        "    Reference:\n",
        "        https://arxiv.org/pdf/1801.07698.pdf\n",
        "        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n",
        "            blob/master/src/modeling/metric_learning.py\n",
        "    '''\n",
        "    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n",
        "                 ls_eps=0.0, **kwargs):\n",
        "\n",
        "        super(ArcMarginProduct, self).__init__(**kwargs)\n",
        "\n",
        "        self.n_classes = n_classes\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.ls_eps = ls_eps\n",
        "        self.easy_margin = easy_margin\n",
        "        self.cos_m = tf.math.cos(m)\n",
        "        self.sin_m = tf.math.sin(m)\n",
        "        self.th = tf.math.cos(math.pi - m)\n",
        "        self.mm = tf.math.sin(math.pi - m) * m\n",
        "\n",
        "    def get_config(self):\n",
        "\n",
        "        config = super().get_config().copy()\n",
        "        config.update({\n",
        "            'n_classes': self.n_classes,\n",
        "            's': self.s,\n",
        "            'm': self.m,\n",
        "            'ls_eps': self.ls_eps,\n",
        "            'easy_margin': self.easy_margin,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(ArcMarginProduct, self).build(input_shape[0])\n",
        "\n",
        "        self.W = self.add_weight(\n",
        "            name='W',\n",
        "            shape=(int(input_shape[0][-1]), self.n_classes),\n",
        "            initializer='glorot_uniform',\n",
        "            dtype='float32',\n",
        "            trainable=True,\n",
        "            regularizer=None)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        X, y = inputs\n",
        "        y = tf.cast(y, dtype=tf.int32)\n",
        "        cosine = tf.matmul(\n",
        "            tf.math.l2_normalize(X, axis=1),\n",
        "            tf.math.l2_normalize(self.W, axis=0)\n",
        "        )\n",
        "        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if self.easy_margin:\n",
        "            phi = tf.where(cosine > 0, phi, cosine)\n",
        "        else:\n",
        "            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        one_hot = tf.cast(\n",
        "            tf.one_hot(y, depth=self.n_classes),\n",
        "            dtype=cosine.dtype\n",
        "        )\n",
        "        if self.ls_eps > 0:\n",
        "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n",
        "\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        output *= self.s\n",
        "        return output"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBm3NIWsRF71"
      },
      "source": [
        "\n",
        "def create_model():\n",
        "\n",
        "    inp = tf.keras.layers.Input(shape=(CFG.img_size, CFG.img_size, 3))\n",
        "    x = EfficientNetB0(include_top = False, weights = 'imagenet')(inp)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Dense(CFG.fc_dim, activation = 'relu')(x)\n",
        "    output = tf.keras.layers.Dense(CFG.classes, activation = 'softmax')(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs = [inp], outputs = [output])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lw8x3AEzfPbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "208c79dc-4c33-433e-e815-9d21b1ad7917"
      },
      "source": [
        "# 2. create_model\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 0s 0us/step\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 384, 384, 3)]     0         \n",
            "_________________________________________________________________\n",
            "efficientnetb0 (Functional)  (None, None, None, 1280)  4049571   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1280)              5120      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               655872    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 11014)             5650182   \n",
            "=================================================================\n",
            "Total params: 10,360,745\n",
            "Trainable params: 10,316,162\n",
            "Non-trainable params: 44,583\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TjS89MmfUMV"
      },
      "source": [
        "# 3. loss and test\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "mean_accuracy_train = tf.keras.metrics.SparseCategoricalAccuracy() "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE1uTXC2XGuG"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBY3JX-tfeZF"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model = CFG.classes)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMXN4w8QCiw_"
      },
      "source": [
        "# Save the model, because colab will crash at any time\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer = optimizer, model = model)\n",
        "\n",
        "manager = tf.train.CheckpointManager(ckpt, '/content/drive/MyDrive/shopee/my_model_b0', max_to_keep=2)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyWr8pvqbiD6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4b7102-8431-4d86-d4ea-01b47909da09"
      },
      "source": [
        "# 手动保存权重\n",
        "\n",
        "def training_model():\n",
        "  \n",
        "    ckpt.restore(manager.latest_checkpoint)\n",
        "    if manager.latest_checkpoint:\n",
        "      print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "    else:\n",
        "      print(\"Initializing from scratch.\")\n",
        "\n",
        "    train_loss_results = []\n",
        "    train_accuracy_results = []\n",
        " \n",
        "    for epoch in tqdm(range(CFG.Epochs)):\n",
        "      train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "      train_acc = tf.keras.metrics.Mean(name='train_acc')\n",
        "\n",
        "      for images, labels in train_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "          probs = model(images)\n",
        "          loss_value = loss_object(labels, probs)\n",
        "          acc = mean_accuracy_train(labels, probs)\n",
        "\n",
        "        grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        # 追踪进度\n",
        "        train_loss(loss_value)  # 添加当前的 batch loss\n",
        "        # 比较预测标签与真实标签\n",
        "        train_acc(acc)\n",
        " \n",
        "        ckpt.step.assign_add(1)\n",
        "\n",
        "        if int(ckpt.step) % 500 == 0:\n",
        "          p_out = 'loss: {}, acc: {}'\n",
        "          print(p_out.format(train_loss.result().numpy(), train_acc.result().numpy()))\n",
        " \n",
        "      save_path = manager.save()\n",
        "      print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
        "\n",
        "      train_loss_results.append(train_loss.result())\n",
        "      train_accuracy_results.append(train_acc.result())\n",
        "\n",
        "      if epoch % 1 == 0:\n",
        "        print(\"Epoch {:03d}: Loss: {:.4f}, Accuracy: {:.4%}\".format(\n",
        "            epoch,train_loss.result(), train_acc.result()))\n",
        "        \n",
        "    return model\n",
        "\n",
        "model = training_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Restored from /content/drive/MyDrive/shopee/my_model_b0/ckpt-10\n",
            "loss: 0.04215363785624504, acc: 0.9824244379997253\n",
            "loss: 0.03807296231389046, acc: 0.984658420085907\n",
            "loss: 0.04302948713302612, acc: 0.9851571917533875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 10%|█         | 1/10 [32:28<4:52:13, 1948.22s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved checkpoint for step 17667: /content/drive/MyDrive/shopee/my_model_b0/ckpt-11\n",
            "Epoch 000: Loss: 0.0444, Accuracy: 98.5216%\n",
            "loss: 0.041136227548122406, acc: 0.9858793616294861\n",
            "loss: 0.0393037274479866, acc: 0.9859554171562195\n",
            "loss: 0.039150919765233994, acc: 0.9860960841178894\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|██        | 2/10 [39:17<3:18:11, 1486.43s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved checkpoint for step 19273: /content/drive/MyDrive/shopee/my_model_b0/ckpt-12\n",
            "Epoch 001: Loss: 0.0420, Accuracy: 98.6148%\n",
            "loss: 0.03822874650359154, acc: 0.9863402247428894\n",
            "loss: 0.035548239946365356, acc: 0.9864304065704346\n",
            "loss: 0.03469464182853699, acc: 0.9865444302558899\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 30%|███       | 3/10 [45:56<2:15:22, 1160.42s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved checkpoint for step 20879: /content/drive/MyDrive/shopee/my_model_b0/ckpt-13\n",
            "Epoch 002: Loss: 0.0351, Accuracy: 98.6622%\n",
            "loss: 0.033139199018478394, acc: 0.9869670271873474\n",
            "loss: 0.030320556834340096, acc: 0.9871546030044556\n",
            "loss: 0.03284657001495361, acc: 0.9873147010803223\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 4/10 [52:46<1:33:31, 935.18s/it] \u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved checkpoint for step 22485: /content/drive/MyDrive/shopee/my_model_b0/ckpt-14\n",
            "Epoch 003: Loss: 0.0322, Accuracy: 98.7397%\n",
            "loss: 0.09573417156934738, acc: 0.9876822829246521\n",
            "loss: 0.02641565352678299, acc: 0.9877457022666931\n",
            "loss: 0.028942985460162163, acc: 0.9878596663475037\n",
            "loss: 0.02902979403734207, acc: 0.9879200458526611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 5/10 [59:35<1:04:47, 777.47s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved checkpoint for step 24091: /content/drive/MyDrive/shopee/my_model_b0/ckpt-15\n",
            "Epoch 004: Loss: 0.0295, Accuracy: 98.7934%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXeAMd05TiRJ"
      },
      "source": [
        "saved_model_path = \"/content/drive/MyDrive/shopee/my_model/tf_model/\"\n",
        "model.save_weights(saved_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf9nUdwajlRF"
      },
      "source": [
        "reconstructed_model = create_model()\n",
        "reconstructed_model.load_weights(saved_model_path)\n",
        "# 重新取输入和输出 选取embedding层作为输出\n",
        "reconstructed_model = tf.keras.models.Model(inputs = reconstructed_model.input[0], outputs = reconstructed_model.layers[-3].output) \n",
        "reconstructed_model.build((None, CFG.img_size, CFG.img_size, 3))\n",
        "reconstructed_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NenF1UR6b9Tf"
      },
      "source": [
        "embeds = []\n",
        "for images, labels in tqdm(val_ds):\n",
        "      embeds.append(model.predict(images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mFWRGQvcL77"
      },
      "source": [
        "image_embeddings = np.concatenate(embeds)\n",
        "test_df_pred, image_predictions = get_image_neighbors(df.iloc[SPLIT:,:], image_embeddings, KNN = 50) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxA_lwwSgzeB"
      },
      "source": [
        "test_df_pred.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEIUx-fEhBH5"
      },
      "source": [
        "len(image_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs43XqFRnoB9"
      },
      "source": [
        "def get_text_predictions(df, max_features=25000):\n",
        "    \n",
        "    model = TfidfVectorizer(stop_words='english', binary=True, max_features=max_features)\n",
        "    text_embeddings = model.fit_transform(df['title']).toarray()\n",
        "\n",
        "    print('Finding similar titles...')\n",
        "    CHUNK = 1024 * 4\n",
        "    CTS = len(df) // CHUNK\n",
        "    if (len(df)%CHUNK) != 0:\n",
        "        CTS += 1\n",
        "\n",
        "    preds = []\n",
        "    for j in range( CTS ):\n",
        "        a = j * CHUNK\n",
        "        b = (j+1) * CHUNK\n",
        "        b = min(b, len(df))\n",
        "        print('chunk', a, 'to', b)\n",
        "\n",
        "        # COSINE SIMILARITY DISTANCE\n",
        "        cts = np.matmul(text_embeddings, text_embeddings[a:b].T).T\n",
        "        for k in range(b-a):\n",
        "            IDX = np.where(cts[k,]>0.75)[0]\n",
        "            o = df.iloc[np.asarray(IDX)].posting_id.values\n",
        "            preds.append(o)\n",
        "\n",
        "    del model,text_embeddings\n",
        "    gc.collect()\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-ygZ1o5nyLS"
      },
      "source": [
        "text_predictions = get_text_predictions(df.iloc[SPLIT:,:], max_features=25000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrBw0SFnp-yZ"
      },
      "source": [
        "# test_df_pred = test_df_pred.iloc[SPLIT:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb7TezdxoTCx"
      },
      "source": [
        "def combine_predictions(row):\n",
        "    x = np.concatenate([row['image_predictions'], row['text_predictions']])\n",
        "    # x = row['image_predictions']\n",
        "    return ' '.join( np.unique(x) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "045XHZ0ynnZ1"
      },
      "source": [
        "test_df_pred['image_predictions'] = image_predictions\n",
        "test_df_pred['text_predictions'] = text_predictions\n",
        "test_df_pred['matches'] = test_df_pred.apply(combine_predictions, axis=1)\n",
        "test_df_pred[['posting_id', 'matches']].to_csv('/content/drive/MyDrive/shopee/submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51Ti4OAzlOi3"
      },
      "source": [
        "test_df_pred.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwngPcJgmWeS"
      },
      "source": [
        "test_df_pred = pd.read_csv('/content/drive/MyDrive/shopee/submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXv26uJ_Lq6z"
      },
      "source": [
        "test_df_pred.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OxIglaULtXT"
      },
      "source": [
        "test_df_pred['f1'] = f1_score(test_df_pred['posting_id'], test_df_pred['matches'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwCTrHBzMG0_"
      },
      "source": [
        "test_df_pred['f1'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3ZgaIJWjytp"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}